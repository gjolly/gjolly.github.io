<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Confidential Computing on Gauthier Jolly</title>
    <link>https://gjolly.fr/tags/confidential-computing/</link>
    <description>Recent content in Confidential Computing on Gauthier Jolly</description>
    <generator>Hugo -- 0.154.5</generator>
    <language>en</language>
    <lastBuildDate>Wed, 21 Jan 2026 17:30:00 +0000</lastBuildDate>
    <atom:link href="https://gjolly.fr/tags/confidential-computing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The trust model of vTPM in Confidential VMs</title>
      <link>https://gjolly.fr/blog/ek-cvm-binding/</link>
      <pubDate>Wed, 21 Jan 2026 17:30:00 +0000</pubDate>
      <guid>https://gjolly.fr/blog/ek-cvm-binding/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://gjolly.fr/blog/confidential-computing-vision/&#34;&gt;In a previous post&lt;/a&gt;, I explained that the direction most Confidential Computing deployments are converging toward is to &lt;strong&gt;reintroduce the TPM abstraction inside the Confidential VM itself&lt;/strong&gt;. Rather than relying on a physical TPM, the goal is to expose a TPM interface from within the TEE.&lt;/p&gt;
&lt;p&gt;This design choice is largely pragmatic. It enables a lift-and-shift model for existing operating systems and workloads that already depend on TPMs for measured boot, disk encryption, and remote attestation. At the same time, it preserves the familiar TPM security guarantees while replacing physical trust assumptions with hardware-enforced isolation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The race toward Confidential AI inference</title>
      <link>https://gjolly.fr/blog/confidential-ai-inference/</link>
      <pubDate>Sun, 18 Jan 2026 15:30:00 +0000</pubDate>
      <guid>https://gjolly.fr/blog/confidential-ai-inference/</guid>
      <description>&lt;p&gt;For almost half a decade now, I have been working on Confidential Computing at Canonical. This position has given me a front-row seat to the evolution of Confidential Computing technologies and their applications.&lt;/p&gt;
&lt;p&gt;One of the most exciting applications is Confidential AI inference, which allows AI models to be hosted and executed in a way that can keep the user&amp;rsquo;s input data confidential, even from the service provider itself.&lt;/p&gt;
&lt;p&gt;While Apple is announcing &lt;a href=&#34;https://blog.google/company-news/inside-google/company-announcements/joint-statement-google-apple/&#34;&gt;a partnership with Google&lt;/a&gt;, to base its own models on Google Gemini and while some might see this as a failure, it is worth noting that Apple Intelligence already has a meaningful legacy.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Attestable Immutable Nodes for Kubernetes</title>
      <link>https://gjolly.fr/blog/confidential-computing-vision/</link>
      <pubDate>Wed, 14 Jan 2026 15:30:00 +0000</pubDate>
      <guid>https://gjolly.fr/blog/confidential-computing-vision/</guid>
      <description>How immutable operating systems and Confidential Computing can provide a trustworthy foundation for Kubernetes worker nodes</description>
    </item>
  </channel>
</rss>
